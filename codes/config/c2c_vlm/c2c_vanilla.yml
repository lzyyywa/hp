#======method setting======
model:
  framework: vlm
  method: c2c_vanilla
  text_encoding_manner: component
  backbone: "ViT-B/32"
  # [CORRECTION] 移除了 switch 开关，默认即为双曲

text:
  text_input_type: template
  input_template_verb: "A verb of  x"
  input_template_obj: "An object of  x"
  learn_input: true
  learn_input_method: coop
  verb_length_type: natural
  ctx_init: true
  #===train===
  text_lr: 0.0001
  text_wd: 0.00001
  ctx_length: 10

data:
  dataset: sth-com
  # 请确认你的具体路径
  dataset_path: "/data/Disk_B/action_data/SS_data/somethingv2/20bn-something-something-v2-frames/"
  num_frames: 8
  num_workers: 4

#======compositional module setting======
c2c:
  nlayers: 2
  fc_emb: 768,1024,1200
  feat_dim: 512
  emb_dim: 300
  relu: False

#======visual encoder setting======
visual:
  pretrained: CLIP
  num_frames: 8
  adapt_star_layer: 6
  num_tadapter: 2
  num_workers: 4
  cosine_scale: 100
  visual_lr: 0.0005
  visual_wd: 0.0001

code_adapt:
  arch: vit
  aux_input: False
  ade_input: False

#======general training setting======
train:
  train_batch_size: 64
  gradient_accumulation_steps: 1
  seed: 0
  epochs: 50
  val_epochs_ts: 45
  warmup: 3
  epoch_start: 0
  save_path: './log/c2c_hyperbolic/'
  load_model: False
  best_model_metric: AUC
  eval_every_n: 5
  save_every_n: 5
  aux_input: False
  ade_input: False

  # [CORRECTION] 显式定义所有损失权重
  # Total Loss = lambda_align * (L_com + att_obj_w * (L_verb + L_obj)) + lambda_entail * L_entail
  loss_weights:
    lambda_align: 0.1   # 判别对齐损失 (Discriminative Alignment) 的总权重
    lambda_entail: 0.1  # 层次蕴含损失 (Hierarchical Entailment) 的权重
    att_obj_w: 0.2      # 动词/物品组件损失的内部权重 (原基线为0.2)

test:
  eval_batch_size: 32
  open_world: False
  topk: 1
  text_encoder_batch_size: 36
  bias: 0.001
  pretrain: False
  load_model: YOUR_PATH